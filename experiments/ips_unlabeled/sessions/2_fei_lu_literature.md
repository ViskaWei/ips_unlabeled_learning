# Session 2: Fei Lu æ–‡çŒ®è°ƒç ”
> **æ—¥æœŸ**: 2026-01-28 | **ç±»å‹**: æ–‡çŒ®è°ƒç ” | **è§¦å‘**: ç”¨æˆ·è¯·æ±‚

---

## 1. è°ƒç ”ç›®æ ‡

ä» [Fei Lu @ JHU](https://math.jhu.edu/~feilu/research.html) çš„ç ”ç©¶ä¸­ï¼Œå¯»æ‰¾ä¸ IPS Unlabeled Learning é¡¹ç›®ç›¸å…³çš„ç†è®ºå’Œæ–¹æ³•ã€‚

---

## 2. Fei Lu èƒŒæ™¯

- **èŒä½**: çº¦ç¿°éœæ™®é‡‘æ–¯å¤§å­¦æ•°å­¦ç³»å‰¯æ•™æˆ (2023â€“è‡³ä»Š)
- **ç ”ç©¶æ–¹å‘**: æ¦‚ç‡è®ºã€ç»Ÿè®¡å­¦åŠå…¶åœ¨ç§‘å­¦è®¡ç®—ä¸­çš„åº”ç”¨
- **æ ¸å¿ƒä¸»é¢˜**: ä»æ•°æ®ä¸­å­¦ä¹ åŠ¨åŠ›å­¦ç³»ç»Ÿ (Learning dynamics from data)
- **åŸºé‡‘**: NSF CAREER Award (DMS-2238486): "Learning kernels in operators from data" â€” $500,000 (2023â€“2028)
- **Google Scholar**: 1,097+ å¼•ç”¨

---

## 3. æ ¸å¿ƒç›¸å…³è®ºæ–‡

### 3.1 Identifiability ç†è®º

#### Paper 1: Identifiability of interaction kernels in mean-field equations
- **ä½œè€…**: Quanjun Lang, Fei Lu
- **å‘è¡¨**: Foundations of Data Science, 2023
- **é“¾æ¥**: [arXiv:2106.05565](https://arxiv.org/abs/2106.05565)

**æ ¸å¿ƒç»“è®º**:
1. Loss functional çš„å”¯ä¸€æœ€å°å€¼**ä»…åœ¨ç‰¹å®šå‡½æ•°ç©ºé—´ä¸­ä¿è¯**
2. å¯è¾¨è¯†çš„å‡½æ•°ç©ºé—´ = **RKHS (å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´)** çš„é—­åŒ…
3. **é€†é—®é¢˜æœ¬è´¨ä¸Šæ˜¯ ill-posed**ï¼Œéœ€è¦æ­£åˆ™åŒ–
4. "identifiability holds on two ambient LÂ² spaces **if and only if** the integral operators are strictly positive"
5. **Weighted LÂ² space** æ¯” unweighted LÂ² space äº§ç”Ÿæ›´å‡†ç¡®çš„ä¼°è®¡

**å…³é”®å¼•ç”¨**:
> "The inverse problem is ill-posed in general."
> "Identifiability holds on any subspace of two reproducing kernel Hilbert spaces (RKHS), whose reproducing kernels are intrinsic to the system and are data-adaptive."

---

#### Paper 2: On the coercivity condition in the learning of interacting particle systems
- **ä½œè€…**: Zhongyang Li, Fei Lu
- **å‘è¡¨**: Stochastic Dynamics
- **é“¾æ¥**: [arXiv:2011.10480](https://arxiv.org/abs/2011.10480)

**æ ¸å¿ƒç»“è®º**:
1. **Coercivity condition** æ˜¯ identifiability çš„æ•°å­¦åŸºç¡€
2. Coercivity âŸº ç§¯åˆ†ç®—å­çš„**ä¸¥æ ¼æ­£å®šæ€§**
3. å½“ç³»ç»Ÿæ˜¯ **ergodicï¼ˆéå†çš„ï¼‰** æ—¶ï¼Œcoercivity æˆç«‹
4. **è‹¥ coercivity ä¸æ»¡è¶³ï¼Œinteraction function ä¸å¯å”¯ä¸€è¾¨è¯†**

**å…³é”®å¼•ç”¨**:
> "In the learning of systems of interacting particles or agents, coercivity condition ensures identifiability of the interaction functions, providing the foundation of learning by nonparametric regression."
> "For a class of interaction functions such that the system is ergodic, the integral kernel is strictly positive definite, and hence the coercivity condition holds true."

---

#### Paper 3: On the identifiability of interaction functions in systems of interacting particles
- **ä½œè€…**: Z. Li, F. Lu, M. Maggioni, S. Tang, C. Zhang
- **å‘è¡¨**: Stochastic Processes and Applications, 132:135â€“163, 2021

**æ ¸å¿ƒç»“è®º**:
1. Coercivity condition æ˜¯ identifiability çš„**å……åˆ†æ¡ä»¶**
2. å½“ç²’å­æ•° Nâ†’âˆ æ—¶ï¼Œcoercivity å˜ä¸º**å¿…è¦æ¡ä»¶**
3. è¯æ˜ä½¿ç”¨äº† **MÃ¼ntz type theorems** æ¥éªŒè¯ç§¯åˆ†æ ¸çš„æ­£å®šæ€§

---

### 3.2 å­¦ä¹ æ–¹æ³•

#### Paper 4: Learning interaction kernels in mean-field equations
- **ä½œè€…**: Quanjun Lang, Fei Lu
- **å‘è¡¨**: SIAM J. Sci. Comput. 44(1), A260â€“A285, 2022
- **é“¾æ¥**: [arXiv:2010.15694](https://arxiv.org/abs/2010.15694)

**æ–¹æ³•**:
- ä½¿ç”¨ **discrete space-time observations of the solution** (ä¸æˆ‘ä»¬çš„ trajectory-free è®¾å®šä¸€è‡´)
- **Least squares with regularization** on data-adaptive hypothesis spaces
- æ”¶æ•›é€Ÿç‡ = æ•°å€¼ç§¯åˆ†å™¨çš„é˜¶

**æˆåŠŸæ¡ˆä¾‹**:
| ä¾‹å­ | Kernel ç±»å‹ | ç»“æœ |
|------|------------|------|
| Opinion dynamics | Piecewise linear | æˆåŠŸ |
| Granular media | Quadratic (smooth) | æˆåŠŸ |
| Aggregation-diffusion | Repulsive-attractive | æˆåŠŸ |
â— è¿™ç¯‡è®ºæ–‡å¤ªå…³é”®äº†ï¼è®©æˆ‘æå–å®éªŒå‚æ•°å’Œæ ¸å¿ƒæ–¹æ³•ã€‚                                  
                                                                                  
  ğŸ“Š å…³é”®å®éªŒå‚æ•°æå–                                                             
                                                                                  
  Table 2: æ•°æ®ç”Ÿæˆå’Œæ¨æ–­è®¾ç½®                                                     
  å‚æ•°: æ—¶é—´åŒºé—´                                                                  
  å€¼: [0, T] = [0, 1]                                                             
  è¯´æ˜:                                                                           
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  å‚æ•°: ç©ºé—´åŸŸ                                                                    
  å€¼: Î© = [-10, 10]                                                               
  è¯´æ˜:                                                                           
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  å‚æ•°: çœŸå®è§£ç½‘æ ¼                                                                
  å€¼: dt = 0.001, dx = 20/3000 â‰ˆ 0.0067                                           
  è¯´æ˜: é«˜ç²¾åº¦                                                                    
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  å‚æ•°: æ•°æ®ç½‘æ ¼                                                                  
  å€¼: Î”t = dt, Î”x = 10dx                                                          
  è¯´æ˜: M = 300 ç©ºé—´ç‚¹                                                            
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  å‚æ•°: é™é‡‡æ ·æµ‹è¯•                                                                
  å€¼: M âˆˆ {300, 250, 200, 150, 120, 100, 60, 50, 40, 30}                          
  è¯´æ˜:                                                                           
  ä¸‰ä¸ªæˆåŠŸæ¡ˆä¾‹çš„è¯¯å·®æ°´å¹³                                                          
  ä¾‹å­: Cubic                                                                     
  Kernel: Ï†(r)=3rÂ² (smooth)                                                       
  Î½: 1.0                                                                          
  æœ€ä¼˜ç»´åº¦: 10 (spline)                                                           
  LÂ²(ÏÌ„_T) è¯¯å·®: 1.90%                                                             
  RKHS è¯¯å·®: 0.43%                                                                
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  ä¾‹å­: Opinion                                                                   
  Kernel: piecewise linear                                                        
  Î½: 0.1                                                                          
  æœ€ä¼˜ç»´åº¦: 28 (spline)                                                           
  LÂ²(ÏÌ„_T) è¯¯å·®: 36.74%                                                            
  RKHS è¯¯å·®: 8.10%                                                                
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        
  ä¾‹å­: Repulsion-attraction                                                      
  Kernel: singular                                                                
  Î½: 0.01                                                                         
  æœ€ä¼˜ç»´åº¦: 30 (spline)                                                           
  LÂ²(ÏÌ„_T) è¯¯å·®: 49.06%                                                            
  RKHS è¯¯å·®: 4.36%                                                                
  å…³é”®å‘ç°ï¼šsmooth kernel å¯ä»¥è¾¾åˆ° <2% è¯¯å·®ï¼                                     
                                                                                  
  ---                                                                             
  ğŸ”‘ ä¸æˆ‘ä»¬é¡¹ç›®çš„å…³é”®åŒºåˆ«                                                         
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       
  â”‚   æ–¹é¢   â”‚        Fei Lu æ–¹æ³•         â”‚ æˆ‘ä»¬å½“å‰æ–¹æ³•  â”‚                       
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       
  â”‚ å­¦ä¹ ç›®æ ‡ â”‚ åªå­¦ Ï†ï¼ˆå•ä¸€ kernelï¼‰      â”‚ åŒæ—¶å­¦ V å’Œ Î¦ â”‚                       
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       
  â”‚ æ­£åˆ™åŒ–   â”‚ RKHS Tikhonov              â”‚ æ— æ­£åˆ™åŒ–      â”‚                       
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       
  â”‚ Loss     â”‚ Quadratic (least squares)  â”‚ å¼±å½¢å¼ PDE    â”‚                       
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       
  â”‚ æ•°æ®     â”‚ Mean-field solution u(x,t) â”‚ ç²’å­åˆ†å¸ƒå¿«ç…§  â”‚                       
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       
  è¿™è§£é‡Šäº†æˆ‘ä»¬å¤±è´¥çš„åŸå› ï¼š                                                        
  1. æˆ‘ä»¬å°è¯•åŒæ—¶å­¦ V å’Œ Î¦ â€” ç†è®ºä¸Šä¸å¯è¡Œ                                         
  2. æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ RKHS æ­£åˆ™åŒ– â€” å¯¼è‡´ ill-posed                                    
                                                                                  
  ---                                                                             
  ğŸ“ Convergence Rate (Theorem 3.7)                                               
                                                                                  
  æœ€ä¼˜æ”¶æ•›ç‡ï¼š                                                                    
  $$|\hat{\phi}{n,M,\infty} - \phi|{\mathbb{H}} \lesssim (\Delta x)^{\frac{\alpha 
  s}{s+1}}$$                                                                      
                                                                                  
  å…¶ä¸­ï¼š                                                                          
  - Î± = æ•°å€¼ç§¯åˆ†å™¨çš„é˜¶ï¼ˆRiemann sum: Î±=1, Trapezoidal: Î±=2ï¼‰                      
  - s = approximation error çš„è¡°å‡é˜¶ï¼ˆÏ† âˆˆ W^{k,âˆ} æ—¶ s=kï¼‰                        
                                                                                  
  æœ€ä¼˜ç»´åº¦ï¼šn â‰ˆ (Î”x)^{-Î±/(s+1)}                                                   
                                                                                  
  ---                                                                             
  âš¡ å¯¹æœ¬é¡¹ç›®çš„ç›´æ¥å¯ç¤º                                                           
                                                                                  
  1. ä¸è¦åŒæ—¶å­¦ V å’Œ Î¦ â€” å‡è®¾ V å·²çŸ¥ï¼Œåªå­¦ Î¦                                      
  2. å®ç° RKHS æ­£åˆ™åŒ– â€” è¿™æ˜¯æˆåŠŸçš„å…³é”®                                            
  3. å‚è€ƒå‚æ•°é…ç½®ï¼š                                                               
    - M = 300 ç©ºé—´ç‚¹                                                              
    - Î½ = 0.01-1.0                                                                
    - å¯¹ smooth kernel æœŸæœ› <2% è¯¯å·®
---

#### Paper 5: Nonparametric learning of kernels in nonlocal operators
- **ä½œè€…**: F. Lu, Qingci An, Yue Yu
- **å‘è¡¨**: J. Peridynamics and Nonlocal Modeling, 2023
- **é“¾æ¥**: [arXiv:2205.11006](https://arxiv.org/abs/2205.11006)

**æ ¸å¿ƒå‘ç°**:
- Kernel learning æ˜¯ **ill-posed æˆ– ill-defined inverse problem**
- å­˜åœ¨ modeling errors æˆ– measurement noises æ—¶ï¼Œestimators **ä¼šå‘æ•£**
- è§£å†³æ–¹æ¡ˆ: **Data adaptive RKHS Tikhonov regularization**

---

### 3.3 ç›¸å…³å·¥ä½œ

#### Paper 6: A data-adaptive prior for Bayesian learning of kernels in operators
- **å‘è¡¨**: JMLR 2024
- **é“¾æ¥**: [JMLR vol.25 no.317](https://jmlr.org/)

---

## 4. å…³é”®å‘ç°ï¼šä¸æœ¬é¡¹ç›®çš„ç›´æ¥å…³è”

### 4.1 è§£é‡Šæˆ‘ä»¬çš„å¤±è´¥

æˆ‘ä»¬çš„ Hub è®°å½•:
- **K1**: Lossâ†’0 ä½†è¯¯å·® >90%
- **ä¿¡å¿µ2âŒ**: å¼±å½¢å¼æ–¹æ³•æ— æ³•åŒºåˆ†ä¸åŒçš„ (V, Î¦) å¯¹

**Fei Lu ç†è®ºè§£é‡Š**:
> "it is not possible, in general, to identify **both** the confining and interaction potentials from a single-particle observation"

**è¿™ç›´æ¥è§£é‡Šäº† MVP-1.0/1.1/1.2 å¤±è´¥çš„æ ¹æœ¬åŸå› **ã€‚

---

### 4.2 Identifiability æ¡ä»¶æ€»ç»“

| æ¡ä»¶ | æè¿° | æˆ‘ä»¬æ˜¯å¦æ»¡è¶³ |
|------|------|-------------|
| **Coercivity** | ç§¯åˆ†ç®—å­ä¸¥æ ¼æ­£å®š | â“ æœªéªŒè¯ |
| **Ergodicity** | ç³»ç»Ÿæ˜¯éå†çš„ | â“ éœ€æ£€æŸ¥ |
| **RKHS æ­£åˆ™åŒ–** | åœ¨ RKHS ä¸­ä¼˜åŒ– | âŒ æœªä½¿ç”¨ |
| **å•ä¸€åŠ¿å‡½æ•°** | åªå­¦ V æˆ–åªå­¦ Î¦ | âŒ åŒæ—¶å­¦ä¸¤ä¸ª |

---

### 4.3 æ–¹æ³•å¯¹æ¯”

| ç»„ä»¶ | Fei Lu æ–¹æ³• | æˆ‘ä»¬å½“å‰æ–¹æ³• |
|------|------------|------------|
| **æ•°æ®** | è½¨è¿¹æ•°æ® / åˆ†å¸ƒå¿«ç…§ | æ— æ ‡ç­¾å¿«ç…§ |
| **Loss** | Least squares + RKHS æ­£åˆ™åŒ– | å¼±å½¢å¼ PDE loss |
| **æ­£åˆ™åŒ–** | Data-adaptive RKHS Tikhonov | æ— æ­£åˆ™åŒ– |
| **ç†è®ºä¿éšœ** | Coercivity â†’ Identifiability | ç¼ºå¤± |

---

## 5. è¡ŒåŠ¨å»ºè®®

### 5.1 ç«‹å³è¡ŒåŠ¨ (P0)

1. **ä¸è¦åŒæ—¶å­¦ä¹  V å’Œ Î¦** â€” ç†è®ºä¸Šä¸å¯è¡Œ
   - æ–¹æ¡ˆ A: å›ºå®š Vï¼Œåªå­¦ Î¦
   - æ–¹æ¡ˆ B: ä½¿ç”¨å·²çŸ¥ Î¦ çš„ç³»ç»ŸéªŒè¯æ–¹æ³•

2. **å®ç° RKHS æ­£åˆ™åŒ–** â€” è¿™ä¸æ˜¯å¯é€‰çš„ï¼Œæ˜¯å¿…é¡»çš„
   - å‚è€ƒ: [arXiv:2205.11006](https://arxiv.org/abs/2205.11006)

3. **é˜…è¯» identifiability è®ºæ–‡** â€” ç†è§£ä½•æ—¶å”¯ä¸€è§£å­˜åœ¨
   - [arXiv:2106.05565](https://arxiv.org/abs/2106.05565)

### 5.2 åç»­è¡ŒåŠ¨ (P1)

1. **éªŒè¯ coercivity condition** â€” æ£€æŸ¥æˆ‘ä»¬çš„ç³»ç»Ÿæ˜¯å¦ ergodic
2. **ä½¿ç”¨ weighted LÂ² space** â€” æ¯” unweighted æ›´å‡†ç¡®
3. **å¤šç³»ç»Ÿè”åˆå­¦ä¹ ** â€” ä¸åŒ V çš„ç³»ç»Ÿå…±äº« Î¦

---

## 6. å…³é”®è®ºæ–‡é“¾æ¥æ±‡æ€»

| è®ºæ–‡ | é“¾æ¥ | é‡è¦æ€§ |
|------|------|--------|
| Identifiability (Lang & Lu) | [arXiv:2106.05565](https://arxiv.org/abs/2106.05565) | æ ¸å¿ƒç†è®º |
| Coercivity (Li & Lu) | [arXiv:2011.10480](https://arxiv.org/abs/2011.10480) | æ ¸å¿ƒç†è®º |
| Mean-field learning (Lang & Lu) | [arXiv:2010.15694](https://arxiv.org/abs/2010.15694) | æ–¹æ³•å‚è€ƒ |
| Nonlocal operators (Lu et al.) | [arXiv:2205.11006](https://arxiv.org/abs/2205.11006) | RKHS æ­£åˆ™åŒ– |
| Identifiability in SPA | [ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0304414920303951) | ç†è®ºè¡¥å…… |
| Network inference | [arXiv:2402.08412](https://arxiv.org/abs/2402.08412) | å¤šç³»ç»Ÿå­¦ä¹  |

---

## 7. å¾…é˜…è¯»è®ºæ–‡ PDF

- [ ] [arXiv:2106.05565](https://arxiv.org/abs/2106.05565) â€” identifiability çš„è¯¦ç»†æ•°å­¦è¡¨è¿°
- [ ] [arXiv:2011.10480](https://arxiv.org/abs/2011.10480) â€” coercivity condition çš„å…·ä½“å½¢å¼
- [ ] [arXiv:2010.15694](https://arxiv.org/abs/2010.15694) â€” å®éªŒçš„å…·ä½“å‚æ•°é…ç½® (N, M, L, Ïƒ)
- [ ] [arXiv:2205.11006](https://arxiv.org/abs/2205.11006) â€” RKHS Tikhonov regularization å®ç°ç»†èŠ‚

---

> **Session ç»“è®º**: Fei Lu çš„ç ”ç©¶æä¾›äº†ç†è®ºåŸºç¡€ï¼Œè§£é‡Šäº†æˆ‘ä»¬å®éªŒå¤±è´¥çš„åŸå› ï¼ˆåŒæ—¶å­¦ä¹  V å’Œ Î¦ ä¸€èˆ¬ä¸å¯è¡Œï¼‰ï¼Œå¹¶æŒ‡å‡ºäº†è§£å†³æ–¹æ¡ˆï¼ˆRKHS æ­£åˆ™åŒ– + ç®€åŒ–é—®é¢˜ï¼‰ã€‚
